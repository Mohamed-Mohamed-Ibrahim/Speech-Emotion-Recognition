{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1877714,"sourceType":"datasetVersion","datasetId":1118008},{"sourceId":11809483,"sourceType":"datasetVersion","datasetId":7410307}],"dockerImageVersionId":31011,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![image.png](attachment:65b9293e-2d96-4789-9bdb-96ad17697d96.png)","metadata":{},"attachments":{"65b9293e-2d96-4789-9bdb-96ad17697d96.png":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAKAAAACfCAYAAAB+49JVAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAABm9SURBVHhe7Z1/bBRnmuc/e+NCS0VD5QYjUSO5uKO5o6Jzz8qdi5sDj8AROCLOaTICewMebA/YBzYGh7FhgKwdZH4zeIgJsY1s5mwQJIsnSkaKJxoTxezGcGNGaUtppDS6NFoa3TS6NJo0Ggotzf34o9vtcru73TYNZez3IxWy6616u4Bvv+9b7/t83+dv/t2/X/T/EAgs4t/EnhAIniZCgAJLEQIUWIoQoMBShAAFliIEKLAUIUCBpQgBCixFCFBgKUKAAksRAhRYihCgwFKEAAWWIgQosBQhQIGlCAEKLEUIUGApQoACSxECFFiKEKDAUoQABZYiBCiwlL9Jry1TYa6uIgOG38PdYGw5oGhkqRDw+HgwuiB6LwCGn9u+eBVYhcJcXcEY89yCxyFtAszIq+VgxYsooYeEAFkC30ArBztdPDJdt7yhk1JbCFd3Fe/1mwooYW/XK2iR+yVpFhLf4env4kT36DqsoYS9XTpD5Q18GlskmDRp6oLz2bzejtF/iJrKCrZVVlDT7UXJK2GdbrpMLiZXC+Lxgj2v0FQwzH2GOsP3bynfwls9PpS8anatt8VeKJgmpKkFLGFvVx53O6s4PTB8TmaOroHPwz0jfCajqJFTeUGOXZCoqZD5XW0T/xQpi9bRVsXpweFzMKfsCCecQU5VH2Zo5PQEkMmuaGSD84dkSmD4v+L9zuNc9UKGXszminzsmc8hcR+/+yNONPdxF0B2sGZ3Oau055H4DnevG7lQi7SAxbzZoXO7D3ILFpEpPSTg7ePY/ovhe5FZWLaHzXkLxnxmsudBzuONhmJWqM/HPI/MwrJaVvMHTk+J3iB9pKkF/JxrPoncsma2rs9jvioDBvc8I+IDlZ84FhH0fs7NwS+4EVrEstejI76E3Ovz4pczyTa3pBMhv5bNTrjWvIVN5dt437Cx7vUCwM66igK0wCfsqy5l85FBDL2YjZGGOWd7Ja8qPs7s2cLmPRe543Ay0g5LyJLGCt3HqfpSatpchLSC6L1z1u9hVx5cO7mNTdWHeD+osamqmoVJnwdytpewAhf7qkvZVPsRAdtPeaMAQGOZ/QUc9iWo0WeYHqRJgH4+a6zj2EAA1VnOwcPttLccYWOBqetUXyFb/Y4b/W5gkEue77DZi5ljriYefgMDGVmJLVDJLipnTdnwUUx2vP8dKfyHrEhAkKv7q9jW3Ae4OVdfwS+P9HLHgEf+L7kTnIVqcwCFrLRJuHuP8ye/wSP/AB987GH0K5HBUG8Xt4PwYLCVK/5ZqLoTUHnVsQD/wGE+dAfB8HD15CDeTJ0VjmTPAxlIIMmEi/p4p7qK9/oAPJyrL2VTfSu3Rz3Ds0+aBAgQ5Eb3Yf6htoJNtf/AaTfkrq9mgz1cOqfQjhaCrKL97G3azxuqBKqdV+OJxowqI2MQ9MUWKMzXbCy2DR8a88eIFOi7yPueELlV73Kmq5Ojh2tZGvlezC2o50BrJ+1dZ2k/Xk2OAkgS8DySFOKBWXGDfgKmXyGI3zXqRAQNRQYtv50zXWfDR+sr2JDCVSd5nj/1XGQoZGdHy1naO06yd3sBc2Orn2akR4B6PqvLCsga/j3oY6jzI4aMeWTZAeystc8j6HNz3evlhtfLDY8LjzGPnKKIQhOwsMiOGvRxzR9b4uGz5gYONQ4fx/nME3sNgJerzbvZVl5KTWMXQ9jZVFVNllpOzXob/p4GaspL2VJZxe+jn/EdoZDEbLOgdYV4+h5LEMMAX/8WNpWXmo7hsW2C5wHw9nF6TxVbyrfxVrcbyf4zdlRNduzxbJAeAQYXkJtfzIYynQwAZOYXvsJi+TvuuAH7yyxWvuVaZwcfdndFjg5Ou74l0/ZyeGwUQ4bq4KXtR9jlkHD1dnAz9oIUmbN+P+2HK5kLPPC5uBydW5SQMLjr8/MIyNDLyY22xv1c84GeV858GcDG8iI7mdFak+HhivdbNEekRQVm59dzoGUPL2Ume55MVjd18naFDQhy1/UFN4ORHhuYrelkaal9BZ4l0vQWDHOLGnmrcBEKhOfxuI+nv4MT3S70ujZ2qC521Hdwz3yTWs7bh53caavi9GB4HtA84RIK3uLSheN8OPgYE9JyHhsP/zeWKQ8xQrOQ+ZbL3Q2cG4Ds7UfY4XieUOghhLx4jRdQ/e/xi+ZBsBWwdfvPcCgPCTGLoOsrDIfCtfIGPo0zJ7i66SyrgpF7sbG8oZ5S23OEQg+RpBDu3uO80+NN8jzGqLlUpFkQ+COnGlu5buhsOL6XbO8hftkWt5l/ZkmbAIeZrelkykH8nnDLMlXIUHVUKc7qiqKRpYYSPu9sTUcOJljVGQ9ZZb4mEYyzepLweSLTV9KolaRCdna8xr3O0VNU04G0C1DwBFArOdCUye8qD/On2LJnnPSMAQVPmK+53PPJtBMfogUUWI1oAQWWIgQosBQhQIGlCAEKLEUIUGApQoACS0m/ABWNLF1jdux5FObqOnPHLGeGz8+JDQ2UVebrOllx7xFMF9I+Dzie58MW+IJd9R2RyOHh86MjoaPryqGHGMxClh7id18ciVYWTBvS2wKm4PkIyk5qypJ4PJy1vFWoEeg/xObKCrZVllLTNkhI/xk7KpLcJ3gmSasAMwp1bIaPD/u8GNqLLI/tVjG4NuBDzStndQItLS+wI3kvcqzbEw0OeDDYwTnXn1Fsr8QN3UqFDL2YrcfbaO86y5muNg7UjQR7Lq5q5sD2EjYcDpe3tx5hQ97Iw8/Or+VAazi49N3D1aze3syBKsfIvXWVbG05y5mu/azOLGFnazMbndHbQa/k7Y4jvGEDbAVs3D0ShDrTSaMAU/F8yCje81wKqPykrCROOL4TXZ2F39s3JjLlZttutu1pnWRcYHL/hyTLZNodyH1N1FQf4qxfYcXr5eEgUbWcXWV2jMFfUVO+jWMuhRWOechyOFJPkmVUux1p4D32HengcuAjrvkVcvLzo5++sMCOFvDwey+gLyFXt5M7veNMUyZ9AkzZ8+Hlw85BAlo+mwvHCjSD+9z1jpzJqQqH8IePanLMlwOoeayM+kLKWVOUF+czk/k/wkh+F6f7/TwyPFzt8xLMVMkGsl63owUGOdXt5gFBbve0cDnGHhDy/oF3ega57fHxAIMrHh+StiTyrHZW2J7H674YjoXsbWJLeQXv9I6uY6aSNgFOyPPh7eDEQBC9sJaXRmnQ4BHPMdfUPQWGQ/gDEpqmjvVIKAtMvhAbi7UFcUPnE/s/wgSD34y6fhhFlsEwTIG0BreD90ddYxij3SKPer7AjY3lBUD+a+TI33Dl46g9UGAiTQKcuOfjbmcXl40XWFdlVuggbv9DNH2ke77dFw7hv2xISAE/N0xXA+A5z3tRX0gDh5rPj3WOJfV/JCdoGCDLplZVJkt5btQ1Y+nnqi+E7iwkx6mB9wuT/1lgJj0CnITnA9yc6/kS7DpqaOTs1Qvh7nlXXWHEjyEzv7CeHU4Fr+ujseJKiWT+j+Tc7vPgz3SyoyKPuZrG4qJaVmixV41lqNdDUHuZNRp4Bk3zUZH5zTHznjOUtAgwu0AnM+AZ06rc63XjU3RWmd8IzQx28Bu3QWQ8H8bbwb6TAwS1v+dg61nOdLVzsEgjONDKsQspNlux+M/zgUtiVcNZ2js6ObVdxYiNhE+Et4OD3S5C9nL2NTSy0e7nknt0FxwX90WGgvNQQx4+Nc+H5leyr66YHNEiwpOYiE4rikaWEozjm5gk4/g/EjFbVQn5R+55aXcn60IdEQNSIlTWHD5Krm+0kSirqpl9qovNjecn9AzTlbS0gE+MoC994iNS3wTFh62Stw7vZ9/uEnJ0Jy9V7KdUB7/HHXtllAxHIWvqalmVeYtLH492sc1XFPy+zyf2DNOY7z3/b3+wL/akwMRfXPyz5/+g2V9ixcoX+Q/SX/jjhYN09v819soof1e4jiU/CHLpwgk++5+mAS7wPflv+WZgkP+d+PYZxdTuggXTnqndBQumPUKAAksRAhRYihCgwFKEAAWWkiYBysyJhM+HDzWyTdvYa2LD6zPUZPc8Lgpzh+0BsoOlZYUsFEtgU4o0TcM42dy6lVzpIUY0xULMpt+Ra+YOlHLoAoCN1U17WKuBEYrcE/yaMycPRzbzTgembdTy6vl1hY6vx6JQqPxq9jqCnIsXLDGDSVMLGMbbP5xiIRxGb9h+xlt1eXFbtjlllazN9HKqNnJP9SF+b9goXR8vlD8NDBznF1bG4akqNpsaN1RsJpNWAZp5MNjFoZ6vkeyv8ZM4kSdapgJBP+7hlTbDw4dHmjjYHc3zMHFkB2uaTkbC7k/yZpG5vy3mzY5GVkZ+m1u0h6ORMPv2lv2scUwgBD/yMwCOag6MV29RI+/mLwD5R9R0NLPBAWBj6fY9ozdyn4E8MQEC0P8l3lAmC03/X8NcH/AQVF/mWFMlLzkj47THXPsdP7WCFN7yVi2nplDD17ONTeVb2OeWWFVUwvxI2Xgh+MM/R06MX29PE9v6b4HxFacq6zjnAtDJtb9ArnNmx+Y/WQES5EFoFlK8fmewhV1H/pHr6JRWHeBUVxtHG8rjvySkFHafSmqFYcKCkWSVDAzudO5my54O7qQYgp+YxPWOpZd3KkvZst+qMcHU4AkLUGG29JCYiPUojzy9/Kaxjm3lW9hxsh9/5svsqiscO2ZMKew+ldQKEfzn+U1/APX1vZzu6uTXxxujXXAqIfgJSVKvID5PVIAZRUvQ8TE0ZliXyeKiclbmDQ8ODe65LvLO4C0k9QXGdEqphN1PKLWCwc3uBn5ZWcrmPa38LpDJq1X1LE0xBF+K26STtF5BfJ6MABWNnPWNHCxchH/gfBw/RADZ5mRdUUk0lQGKkw0OlZDfx+T2gZ9AaoW8Wo627GGpDI/8Lq65A+HpoxRC8H1BA1lbwlIFQCEn3zYi8iT1jiU8LxpOazZzSe88oOnfMmT8maHeLs70DhvMY+YB5Tw2NJSwQh1pXUKBrzjbNpzUbxKknFrBxuqmetZqEkYIZHMaBWB2fjU7XnegymD4B7gUdPIqXeEI6GiaBYD7eNx+VLvEpfHqVQt5s+HvscsP8fRU8KveQnZ2/BQ+ruBXM3gYmCYBPgayynxNIZQowfUkSDm1QoIQ/cmF4JtIUO8o9GqO7la5XN3Ap2N6iJmD9RHRob/y10CAB/8aWzB5HgVTrO9fg9wL/JX/az5nq2Rf0wZW6N/nLwGZrNe3UOr4Pv/rn7u5GhPdnJB49cbiWMlPVD9dvS5SedTpivUt4BQkQy+ktOjHLFZlQgE/Q72tj5etKR72AlYqbj4bmKTTb5ogBCiwlCfzFiwQpIgQoMBShAAFliIEKLAUIUCBpQgBCiwlTdMw4STLY5bojUhCZkUjK86aZ9Dn4Z55FUDRyFIhECfB82TI0PNZ+/rLLAx5+E3z+QRhUQIrSZMAR3tCovj62Lb/Iqzfz5mCBYRCDxlZSwhyrW04ODNM4hQPkyGfra0/Rw98yRX3l/y2ZyDxspjAMtIqwBHDUQzr93MmL8iJ6uNcjy0bRi5mZ4sTfDI2PklDoGYJe7sc3NxTxwcze7FhSjNlxoDjp3iYAEWNvNuRj415rGjq5N2GYgAyHOXsbOkM+zVaj7DZ5MdIlsZhZUMnO6sq2dt6ljOt9WQjs7BsD1vLHGODZwUT4ikKUEriHU4lxcME6GliW2U/Xm7xu8qK8DBALWFXVR6Sq4Wa8i3s6w2yeH01G+yMn8ZBmoXusHHzwiH2nTyPB41l9hdw2JcQx28lmABpFaCtIOwGCx9tbDZvzSu/wKbde9k3fGwvGYl8TjnFA4BKdpHJH1JWTHYKKphT6MAWGOBYt5sHGNzpbeGSbx45+Y6U0jgEXF18MOCJbHDp4Vx9KZvqW+NEZgsmQloF6O0rZVP58DGS+w0A4ytORMtK2WQaD04oxQMK8zWTP8SmMX/M6/dYNEUG9WVOR78g7azVRlI1jJ/GYXJx2oLkpFWAk2OiKR48fNZs8oc0HuezFLQRNAzwf85m85egvDQcZPoYaRwEj4f1ApxUioeJc3vAS0B1sCk/0lwq+Ww+fpKtBZmTSuMwW9PJ0lJoegVJeXoClH/Ejmj3NzJGnHSKh4nibuVYb4DFZe/S3tFJe8vPWRwc4IO+wCTSOOis3b6XmsJxVCoYlzTNAz5LhFdtpHgelFS8HAAUsrPjNe51xoxzBRPm6bWAUwaDe5444mMCaRzUH6LgwyXE99jMQAGmg6+53PMJf4o9LZgwM7ALFkwlRAsosBQhQIGlCAEKLEUIUGApQoACSxECFFhKmgQYPwdIOE9HvPT04fNjr08l38hEMeUKEUw50jQPmCgkv4S9XXncbYtZsipspL1oESHPf2fbEbP5I9ZbMgtZuo+nv4MT3a7xVyjiYt4XUDDVSFMLOBFkljs0gt5vCNl+zPLYYlO+kW2VpdR0+1DzS1gXLzJL8Mzz9AUov0auZnDj4z9wI6SROyqXx1ge9H/ODWMeWY8pQKWokaMdZznT1cnRhuKo3yOZF2RxVTMHtpew4XBbHB9JOO/ImqJGft0Vqbcpsst/Zgk7W5vZaI7k0St5u+MIb9jCO7lu3F3L0pmdIgTSLUBJNo/fdLJ0ecz+yHOKHOiGl8vuQa54Q+j2nyYf58kLmCM9JBQveCBlVJbpPk7Vl1LT5iKkFUT8HuN4QWQZ1ZHHfHcrNeXbODgYIifqI5GQpUWscgZ5f88WNu85z00lsst/4COu+RVy8vOjT7CwwI4W8PB7L6AvIVe3kztmN/aZR1oFqDnr2VVnPpyY9vcGVFbpPyTg/ZybwPU+DwHNPiaTkqIN+z0q2dpUgG54+DSOTzirwOwNKeelhK2kwVBvF7eD8GCwlSv+Wai6MyUvCAEXpy9EcoZ0t3I5MI/svGHlPMTT1xLJS9LP6d6vCWkvsgyDKx4fkraEHADsrLA9j9d9MZz+obeJLVamDZtCpFWAI2O34aOfUfuNq6+Roz5EUovZ27SfvUUqEj8kJyawU84c8XtI/n6ONR7nepx9lDPNuUNsNvS4W+IDBPGbDPBmxvWC+L825Qzxc91/H0kefn0PcNucgmLAT0CSkIFHPV/gxsbyAiD/NXLkb7jycZy/xAwnrQIcj4VFdlTDxzVPxPvh9XDNex/VXjwq9N7vGvF8vNN8nhsJut+hNrM3pIFzcVrJpKTgBVEyF5mGCDKLM5+D0PD+DgqZ5jRkjkwUiOz+0M9VXwjdWUiOUwPvF3HSVQieogDD3ZDf1cEHUe9HFx90uvArNlYk7D6fJCl4QVQHm/LCL0oZedUsU+/jdQ83p8+RU1ASeWmxsbpAR/F7uRYpHer1ENReZo0GnkHTt0NWmR93fnTm8fQE6HyFbOVbrvfGNDH+TxjyP092QbrMHxMgBS9I0ONh9vp22js6OV2hYwye53RUS7cY8js42NVJe9fbrM30cbaza6TLdl9kKDgPNRQzhs2vZF9dMTmiRUzXRPQzTgIvSHZdGxvp4hfNbuboGozazcs0wa1oZCnBOJk+VdYcPkqu7xC/bBvxjmZVNbNPdbG58fwkJ9enD0+vBZzKjOsFCftIRm0lZyZOmtkMRyFr6mpZlXmLSx+PNi7PVxT8vs+TfN7MQQgwCUG/F68/tlUb5s/c9vkT7jlod7zIYjnAb9sO81nMqOOOq48PYociMxTRBQssRbSAAksRAhRYihCgwFKEAAWWIgQosBQhQIGlpGkaJrzjlBz0ccdvnq2N2Ykqab6QRLtWKczVVRhz/tkn5czu05g0ZUx3UN5UR+lyG/7+Af4cTQYSPv/jv/2IL9zAmnpOlP1Xljmd/JelS1m2dCnLlv4nvv8vfXzlj7k2ylp2HP85//l7seenAPnV7F3zH/mX/+E2hWylzqq6X/PaD6bg3+spksYu+CFBbKyrykse4Wx8xalRMYOjk9U8U6gqNps6NkOUIGXSKEDwDboI2Yuj4UtThZUNnbxZVsybwzlCWhpZbvJjJM4fEvZ9rBy5lJUNnRyocoRzkeQvAPlH1HQ0s8ER8ZDUVbK15SxnuvazehzPiSCtApyFHOrinFsit6iS7NjiKMnyhTwZJGkWulPndmcdm2rf40pIY936iPEjaf4QCVmSRvlaJGkWsiyFc5H034q06OFWXJJlVLsdaeA99h3p4PI4nhNBWgUIYHC97SPc0otsqEoQYZosX8hEUfNYafKErCnKS5BbBAzPJ3zoDkJwkHMuP5L6Atnj5g+ZOCHvH3inZ5DbHh8PUvGczHDSLEDA6OPUx18jO8vDFsRYkuQLmTDKglGekMXagoTjsUAg/kBzvPwhE8UwAqN+H89zMtNJvwCBR30t/NarsKLsxxPYEiNEKASyHBMTr8rI3OfuKHdTBM953jN5Qg41n59w5qKk+UMAkFFiw/RTJQXPyUzniQgQDP6psx+fqmNL+cvu4pr3O1RnLW84h3N52FlT5UQNerjyhDYET54/5FuM0DyyC3UyEnlGkpKC5yTC3IJatlYVJBxCTFeekADDfovT/f6xvU2CfCEA10+2cMYjsaLq3XBZy05WKT7OnmyZfDc9Hsnyh9DHuf5bKHl7Od11llNVCnfMPWz/H3HzI3Z0dbIz3otFCp6TYRY77TgcS5K8vE1P0rQSkm6sWP1ItBKTBhJ4TgRTVoCCmcKT64IFghQQAhRYihCgwFKEAAWWIgQosBQhQIGlCAEKLEUIUGApQoACSxECFFiKEKDAUoQABZYiBCiwFCFAgaUIAQosRQhQYClCgAJLEQIUWIoQoMBShAAFliIEKLAUIUCBpQgBCixFCFBgKUKAAkv5/3rJvqi2gNNRAAAAAElFTkSuQmCC"}}},{"cell_type":"markdown","source":"# Resourses\n- https://www.kaggle.com/code/dmitrybabko/speech-emotion-recognition-conv1d\n- https://www.kaggle.com/code/shivamburnwal/speech-emotion-recognition\n- https://librosa.org/doc/latest/index.html\n- https://www.kaggle.com/code/hossamemamo/speech-emotion-recognition-2-parallel-cnn-conv-2d\n- https://www.kaggle.com/code/shivamburnwal/speech-emotion-recognition\n- ","metadata":{}},{"cell_type":"code","source":"\n\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"  # Optional: reduce TF logging\n\nimport tensorflow as tf\n\n# GPU Memory Growth Setup — MUST BE BEFORE ANY OTHER TF/KERAS CALL\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(\"✅ GPU detected and memory growth set:\", gpus)\n    except RuntimeError as e:\n        print(\"⚠️ Could not set memory growth:\", e)\nelse:\n    print(\"❌ No GPU detected. Using CPU.\")\n\n# ✅ NOW safe to import the rest\nimport librosa\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport sys\nimport warnings\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\nfrom IPython.display import Audio\nimport torch\nfrom sklearn.preprocessing import OneHotEncoder\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T23:58:35.650079Z","iopub.execute_input":"2025-05-14T23:58:35.650338Z","iopub.status.idle":"2025-05-14T23:58:53.031233Z","shell.execute_reply.started":"2025-05-14T23:58:35.650317Z","shell.execute_reply":"2025-05-14T23:58:53.030439Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T01:03:55.767098Z","iopub.execute_input":"2025-05-15T01:03:55.767392Z","iopub.status.idle":"2025-05-15T01:03:55.771294Z","shell.execute_reply.started":"2025-05-15T01:03:55.76737Z","shell.execute_reply":"2025-05-15T01:03:55.770683Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Paths to\nRavdess = \"../input/speech-emotion-recognition-en/Ravdess/audio_speech_actors_01-24\"\nCrema = \"../input/speech-emotion-recognition-en/Crema\"\nSavee = \"../input/speech-emotion-recognition-en/Savee\"\nTess = \"../input/speech-emotion-recognition-en/Tess\"\nprint(os.listdir(Ravdess))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T23:58:53.032543Z","iopub.execute_input":"2025-05-14T23:58:53.033292Z","iopub.status.idle":"2025-05-14T23:58:53.047803Z","shell.execute_reply.started":"2025-05-14T23:58:53.033265Z","shell.execute_reply":"2025-05-14T23:58:53.047029Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"emotion_df = []\n\nfor wav in os.listdir(Crema):\n    info = wav.partition(\".wav\")[0].split(\"_\")\n    if info[2] == 'SAD':\n        emotion_df.append((\"sad\", Crema + \"/\" + wav))\n    elif info[2] == 'ANG':\n        emotion_df.append((\"angry\", Crema + \"/\" + wav))\n    elif info[2] == 'DIS':\n        emotion_df.append((\"disgust\", Crema + \"/\" + wav))\n    elif info[2] == 'FEA':\n        emotion_df.append((\"fear\", Crema + \"/\" + wav))\n    elif info[2] == 'HAP':\n        emotion_df.append((\"happy\", Crema + \"/\" + wav))\n    elif info[2] == 'NEU':\n        emotion_df.append((\"neutral\", Crema + \"/\" + wav))\n    else:\n        emotion_df.append((\"unknown\", Crema + \"/\" + wav))\n\n\nCrema_df = pd.DataFrame.from_dict(emotion_df)\nCrema_df.rename(columns={1 : \"Path\", 0 : \"Emotion\"}, inplace=True)\n\nCrema_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T23:58:53.048449Z","iopub.execute_input":"2025-05-14T23:58:53.048619Z","iopub.status.idle":"2025-05-14T23:58:53.1662Z","shell.execute_reply.started":"2025-05-14T23:58:53.048606Z","shell.execute_reply":"2025-05-14T23:58:53.165409Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df = pd.concat([Ravdess_df, Crema_df, Tess_df, Savee_df], axis=0)\ndf = pd.concat([Crema_df], axis=0)\ndf.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T23:58:53.167699Z","iopub.execute_input":"2025-05-14T23:58:53.167935Z","iopub.status.idle":"2025-05-14T23:58:53.173238Z","shell.execute_reply.started":"2025-05-14T23:58:53.167908Z","shell.execute_reply":"2025-05-14T23:58:53.172493Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%matplotlib inline\n\nplt.style.use(\"ggplot\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T23:58:53.174164Z","iopub.execute_input":"2025-05-14T23:58:53.174425Z","iopub.status.idle":"2025-05-14T23:58:53.188246Z","shell.execute_reply.started":"2025-05-14T23:58:53.174402Z","shell.execute_reply":"2025-05-14T23:58:53.187608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.title(\"Count of emotions:\")\nsns.countplot(x=df[\"Emotion\"])\nsns.despine(top=True, right=True, left=False, bottom=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T23:58:53.18896Z","iopub.execute_input":"2025-05-14T23:58:53.189263Z","iopub.status.idle":"2025-05-14T23:58:53.447992Z","shell.execute_reply.started":"2025-05-14T23:58:53.189246Z","shell.execute_reply":"2025-05-14T23:58:53.447262Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_waveplot(data, sr, e):\n    plt.figure(figsize=(10, 3))\n    plt.title(f'Waveplot for audio with {e} emotion', size=15)\n    librosa.display.waveshow(data, sr=sr)\n    plt.show()\n\ndef create_spectrogram(data, sr, e):\n    # stft function converts the data into short term fourier transform\n    X = librosa.stft(data)\n    Xdb = librosa.amplitude_to_db(abs(X))\n    plt.figure(figsize=(12, 3))\n    plt.title('Spectrogram for audio with {} emotion'.format(e), size=15)\n    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')\n    plt.colorbar()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T23:58:53.448856Z","iopub.execute_input":"2025-05-14T23:58:53.449079Z","iopub.status.idle":"2025-05-14T23:58:53.454498Z","shell.execute_reply.started":"2025-05-14T23:58:53.449063Z","shell.execute_reply":"2025-05-14T23:58:53.453819Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"emotion='fear'\npath = np.array(df.Path[df.Emotion==emotion])[1]\ndata, sampling_rate = librosa.load(path)\ncreate_waveplot(data, sampling_rate, emotion)\ncreate_spectrogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T23:58:53.455286Z","iopub.execute_input":"2025-05-14T23:58:53.455545Z","iopub.status.idle":"2025-05-14T23:59:05.772151Z","shell.execute_reply.started":"2025-05-14T23:58:53.455523Z","shell.execute_reply":"2025-05-14T23:59:05.77149Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"emotion='angry'\npath = np.array(df.Path[df.Emotion==emotion])[1]\ndata, sampling_rate = librosa.load(path)\ncreate_waveplot(data, sampling_rate, emotion)\ncreate_spectrogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T23:59:05.773206Z","iopub.execute_input":"2025-05-14T23:59:05.773921Z","iopub.status.idle":"2025-05-14T23:59:06.601557Z","shell.execute_reply.started":"2025-05-14T23:59:05.773875Z","shell.execute_reply":"2025-05-14T23:59:06.600907Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"emotion='sad'\npath = np.array(df.Path[df.Emotion==emotion])[1]\ndata, sampling_rate = librosa.load(path)\ncreate_waveplot(data, sampling_rate, emotion)\ncreate_spectrogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T23:59:06.60535Z","iopub.execute_input":"2025-05-14T23:59:06.60581Z","iopub.status.idle":"2025-05-14T23:59:07.645727Z","shell.execute_reply.started":"2025-05-14T23:59:06.605788Z","shell.execute_reply":"2025-05-14T23:59:07.644939Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data augmentation\n\nWe have some ways for data augmentation in sound data:\n\n1. Noise injection\n2. Stretching\n3. Shifting\n4. Pitching","metadata":{}},{"cell_type":"code","source":"def noise(data, random=False, rate=0.035, threshold=0.075):\n    \"\"\"Add some noise to sound sample. Use random if you want to add random noise with some threshold.\n    Or use rate Random=False and rate for always adding fixed noise.\"\"\"\n    if random:\n        rate = np.random.random() * threshold\n    noise_amp = rate*np.random.uniform()*np.amax(data)\n    data = data + noise_amp*np.random.normal(size=data.shape[0])\n    return data\n\ndef stretch(data, rate=0.8):\n    \"\"\"Stretching data with some rate.\"\"\"\n    return librosa.effects.time_stretch(data, rate=rate)\n\ndef shift(data, rate=1000):\n    \"\"\"Shifting data with some rate\"\"\"\n    shift_range = int(np.random.uniform(low=-5, high = 5)*rate)\n    return np.roll(data, shift_range)\n\ndef pitch(data, sampling_rate, pitch_factor=0.7, random=False):\n    \"\"\"\"Add some pitch to sound sample. Use random if you want to add random pitch with some threshold.\n    Or use pitch_factor Random=False and rate for always adding fixed pitch.\"\"\"\n    if random:\n        pitch_factor=np.random.random() * pitch_factor\n    return librosa.effects.pitch_shift(y=data, sr=sampling_rate, n_steps=pitch_factor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T23:59:07.646578Z","iopub.execute_input":"2025-05-14T23:59:07.64685Z","iopub.status.idle":"2025-05-14T23:59:07.654742Z","shell.execute_reply.started":"2025-05-14T23:59:07.64683Z","shell.execute_reply":"2025-05-14T23:59:07.653994Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T23:59:07.655875Z","iopub.execute_input":"2025-05-14T23:59:07.656138Z","iopub.status.idle":"2025-05-14T23:59:07.67644Z","shell.execute_reply.started":"2025-05-14T23:59:07.656122Z","shell.execute_reply":"2025-05-14T23:59:07.675822Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2D","metadata":{}},{"cell_type":"code","source":"n_fft = 2048\nhop_length = 512","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T23:59:07.677096Z","iopub.execute_input":"2025-05-14T23:59:07.677383Z","iopub.status.idle":"2025-05-14T23:59:07.68951Z","shell.execute_reply.started":"2025-05-14T23:59:07.677357Z","shell.execute_reply":"2025-05-14T23:59:07.688971Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchaudio\nimport torchaudio.transforms as transforms\nfrom tqdm import tqdm\n\nS_dB_Total = []\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nfor idx, path in tqdm(enumerate(df.Path)):\n    waveform, sample_rate = torchaudio.load(path)\n\n    if waveform.shape[0] > 1:\n        waveform = waveform.mean(dim=0, keepdim=True)\n    \n    # Convert to tensor\n    waveform = torch.tensor(waveform).to(device)\n\n    # Convert to mel spectrogram\n    mel_transform = transforms.MelSpectrogram(\n        sample_rate=sample_rate,\n        n_fft=2048,\n        hop_length=512,\n        n_mels=128\n    ).to(device)\n    \n    S = mel_transform(waveform)\n\n    # Convert to dB\n    power_to_db = transforms.AmplitudeToDB()\n    S_dB = power_to_db(S)\n\n    S_dB_Total.append(S_dB.squeeze())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T23:59:07.690215Z","iopub.execute_input":"2025-05-14T23:59:07.690416Z","iopub.status.idle":"2025-05-15T00:01:16.300043Z","shell.execute_reply.started":"2025-05-14T23:59:07.690392Z","shell.execute_reply":"2025-05-15T00:01:16.299236Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sizes=[]\nfor x in S_dB_Total:\n    sizes.append(x.shape[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:16.300881Z","iopub.execute_input":"2025-05-15T00:01:16.301371Z","iopub.status.idle":"2025-05-15T00:01:16.308181Z","shell.execute_reply.started":"2025-05-15T00:01:16.301344Z","shell.execute_reply":"2025-05-15T00:01:16.307466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate the bin counts\nbincount_array = np.histogram(sizes, bins=np.arange(min(sizes), max(sizes)+2))[0]\n\n# Create a list of labels for the x-axis\nx_labels = np.arange(min(sizes), max(sizes)+1)\n\n# Plot the bin counts as a bar plot\nplt.bar(x_labels, bincount_array)\n\n# Set labels and title\nplt.xlabel('Numbers')\nplt.ylabel('Count')\nplt.show()\n\nprint(f'min is {min(sizes)}')\nprint(f'max is {max(sizes)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:16.308836Z","iopub.execute_input":"2025-05-15T00:01:16.309045Z","iopub.status.idle":"2025-05-15T00:01:16.551915Z","shell.execute_reply.started":"2025-05-15T00:01:16.309029Z","shell.execute_reply":"2025-05-15T00:01:16.551224Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\npadding_length = 160\npadded_list = []\nfor array in S_dB_Total:\n    current_shape = array.cpu().shape\n    padding = [(0, 0), (0, padding_length - current_shape[1])]\n    padded_array = np.pad(array.cpu(), padding, mode='constant', constant_values=0)\n    padded_list.append(padded_array)\n\n# Convert the padded list to a NumPy array\ndata_2D = np.array(padded_list)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:16.552777Z","iopub.execute_input":"2025-05-15T00:01:16.553531Z","iopub.status.idle":"2025-05-15T00:01:18.477148Z","shell.execute_reply.started":"2025-05-15T00:01:16.553505Z","shell.execute_reply":"2025-05-15T00:01:18.476372Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_2D.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:18.477945Z","iopub.execute_input":"2025-05-15T00:01:18.478138Z","iopub.status.idle":"2025-05-15T00:01:18.482853Z","shell.execute_reply.started":"2025-05-15T00:01:18.478124Z","shell.execute_reply":"2025-05-15T00:01:18.482244Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.Emotion.unique()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:18.483623Z","iopub.execute_input":"2025-05-15T00:01:18.483958Z","iopub.status.idle":"2025-05-15T00:01:18.4959Z","shell.execute_reply.started":"2025-05-15T00:01:18.483928Z","shell.execute_reply":"2025-05-15T00:01:18.495331Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.Emotion.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:18.496655Z","iopub.execute_input":"2025-05-15T00:01:18.496897Z","iopub.status.idle":"2025-05-15T00:01:18.511735Z","shell.execute_reply.started":"2025-05-15T00:01:18.496881Z","shell.execute_reply":"2025-05-15T00:01:18.511174Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#normalization\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Reshape the array to 2D\nreshaped_data = data_2D.reshape((-1, 1))\n\n# Initialize the MinMaxScaler\nscaler = MinMaxScaler()\n\n# Fit and transform the data\nnormalized_data = scaler.fit_transform(reshaped_data)\n\n# Reshape the normalized data back to the original shape\nnormalized_data = normalized_data.reshape(data_2D.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:18.512429Z","iopub.execute_input":"2025-05-15T00:01:18.512683Z","iopub.status.idle":"2025-05-15T00:01:19.242237Z","shell.execute_reply.started":"2025-05-15T00:01:18.512661Z","shell.execute_reply":"2025-05-15T00:01:19.241378Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"normalized_data[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:19.243132Z","iopub.execute_input":"2025-05-15T00:01:19.243393Z","iopub.status.idle":"2025-05-15T00:01:19.25024Z","shell.execute_reply.started":"2025-05-15T00:01:19.243369Z","shell.execute_reply":"2025-05-15T00:01:19.249492Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data=np.expand_dims(normalized_data, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:19.250992Z","iopub.execute_input":"2025-05-15T00:01:19.251323Z","iopub.status.idle":"2025-05-15T00:01:19.265554Z","shell.execute_reply.started":"2025-05-15T00:01:19.251299Z","shell.execute_reply":"2025-05-15T00:01:19.264791Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels=df.Emotion.replace({'disgust': 1, 'happy': 2, 'sad': 3, 'neutral': 4, 'fear': 5, 'angry': 6}).to_numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:19.266535Z","iopub.execute_input":"2025-05-15T00:01:19.266793Z","iopub.status.idle":"2025-05-15T00:01:19.287616Z","shell.execute_reply.started":"2025-05-15T00:01:19.266774Z","shell.execute_reply":"2025-05-15T00:01:19.286801Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:19.288364Z","iopub.execute_input":"2025-05-15T00:01:19.288563Z","iopub.status.idle":"2025-05-15T00:01:19.298373Z","shell.execute_reply.started":"2025-05-15T00:01:19.288547Z","shell.execute_reply":"2025-05-15T00:01:19.297699Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.unique(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:19.298957Z","iopub.execute_input":"2025-05-15T00:01:19.299129Z","iopub.status.idle":"2025-05-15T00:01:19.312334Z","shell.execute_reply.started":"2025-05-15T00:01:19.299114Z","shell.execute_reply":"2025-05-15T00:01:19.311702Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:19.313239Z","iopub.execute_input":"2025-05-15T00:01:19.313528Z","iopub.status.idle":"2025-05-15T00:01:19.32796Z","shell.execute_reply.started":"2025-05-15T00:01:19.313505Z","shell.execute_reply":"2025-05-15T00:01:19.327223Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# torch.save({\n#     'data': torch.tensor(data_2D),  \n#     'labels': torch.tensor(labels) \n# }, 'dataset.pt')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:19.332069Z","iopub.execute_input":"2025-05-15T00:01:19.33229Z","iopub.status.idle":"2025-05-15T00:01:19.341982Z","shell.execute_reply.started":"2025-05-15T00:01:19.332275Z","shell.execute_reply":"2025-05-15T00:01:19.341235Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = np.transpose(data, (0, 2, 3, 1))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:19.342817Z","iopub.execute_input":"2025-05-15T00:01:19.34322Z","iopub.status.idle":"2025-05-15T00:01:19.356382Z","shell.execute_reply.started":"2025-05-15T00:01:19.343195Z","shell.execute_reply":"2025-05-15T00:01:19.355613Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:19.357153Z","iopub.execute_input":"2025-05-15T00:01:19.357477Z","iopub.status.idle":"2025-05-15T00:01:19.369244Z","shell.execute_reply.started":"2025-05-15T00:01:19.357454Z","shell.execute_reply":"2025-05-15T00:01:19.368519Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:19.369975Z","iopub.execute_input":"2025-05-15T00:01:19.370283Z","iopub.status.idle":"2025-05-15T00:01:19.384563Z","shell.execute_reply.started":"2025-05-15T00:01:19.370257Z","shell.execute_reply":"2025-05-15T00:01:19.383822Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Final Size\n\n![image.png](attachment:aa83c467-cf79-4e38-9320-5cbd8d9abc3c.png)","metadata":{},"attachments":{"add8bc9a-e8c6-4903-88ce-4d4babeacda7.png":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAALsAAAAnCAYAAABXNDlSAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAASmSURBVHhe7Zu/buJYFMa/2W41O242lkarFAveFLgZohThAeJoemiIIiG/wE6aRBSTFIQigiazL4AiIWigR3EegCkQ0ECBDE06p/IDzGzhf9fGJoawG8g9P4mCe30u95773XOObfHuz8RfP8Hw8eMf+H1nB799+ICfP37g1/fv2W6C2FreBcVOEG+VX4INBPFWIbET3EBiJ7iBxE5wA4md4AYSO8ENJHaCG0jsBDeQ2AluILET3EBiJ7iBxE5ww1Jir2oTDBuFYDPBDQU0Bz001WD7dhBb7Gqjh5z4Hbcnd0zrDR6mE8ymEzxUmGYAqHQws/tm0w6qvs4FdiigOXDs/P1VzWufaTes0cqojZ413qCO9eyhN/+5wKDWMXR94heNOw/7M2e7EtG+9PYnuDfw7Y9/nnfIfxtDvgyz2XziiV2t4yxjoJU+RY1pG04VGNdt6P6rLWflgFZyD4nkHlq6hJwjzufspl8hj8pI2LZHF3ZXpYMc2nZ7G7qUDTkoy1HVJrgSNZS6ZrBrRaz5i/dlzA9ZQPNLCqNra12lLpD5Yh8wtY4zeYySveZEsg0jk3+hoKJ9qTZ6mB0/odSa3wFrf7JAy5nLAfLupgOoneK2K3r7uUXEEnv15BDoNnHONtZO8SnoCJcijpKf3evP+zog7lobu8iukoakt/HJlz1sLj4joRTtL0VYQ74s+p0re8yY66CII/aA+rhDPu2tu6aNYQo7kAGg9ghDOMSZHc3VhgLJfMLIZ78kC3xZOzlAgg1cDKqSArrliDVY1E406JKydeVMDLEXsCuaGGnzTotLdV+COdJCnctS3ZdgGrsRKZTlBvvSy+b02qhKCoI+sANCEUfJMkbyV8ymVraJEmNc4vuSpYBjWYABhSm3wkqWIvq6AFl5WbD5v4kh9hREwcDjip4Pr/WjETI76DvpvGV4qd6lgOYgC7H7T3h22AYqHVxlDLTcrMKWHGV0xexa7iGe92U4kgzc2naliJJlZMzVaRtPDLGvjtro4Uoeo7RElDLZcmn85KV6wBa6JYqw9LwVVDqY5YAWU+ahkoZkOgHhDvl0G7qQwnEcZS5gsS+j0e+9/ao9Gl4JuuXEEPsYhilid8nVVrXJ0kI/7+sQZMV1rD/Ve9EvXOjOk4ewtLsq9lOJNURZODeGQaE7sEJUdyH6e92nNXFvyhf7Moo73I9MSPteJI8qQWVRgPEYtg+bS6w/XFe1CY6NoMhu8DDNQmJaABPd6wPkUcfw8hCCrw/QW3s4ulhgV7N+K+d0mt/dw6I2erjKzI3oE45l6431HKFj6m3mptXKJBnB/zvRONf7W6PXDZhdy6/BuVg2zIWVDmY5yb0+DlG+dMby4fYH1uDzh8MNHqYKjJh+3hRiiR1qHcPLHdzH2vBXJKxEeCGrlGL/DdZhQfAQvAJqo2fdRM8dgs0mRhnDPFtdUzpfP3a5sU6h2y+ANkHo1su0zRC6+85ly4SO2JHdpqpNsN/fAIcTr0QBzcHfwLftKl8clhI7QWwz8coYgngDkNgJbiCxE9xAYie4gcROcAOJneAGEjvBDSR2ghtI7AQ3kNgJbiCxE9xAYie44V/7zmFRnnUkdAAAAABJRU5ErkJggg=="},"aa83c467-cf79-4e38-9320-5cbd8d9abc3c.png":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAALUAAAAkCAYAAADPaXtPAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAStSURBVHhe7Zu9buJaFIXX3AdwFXcpJvFNgZtJlCJ+gDFKDw3cSJZfYHKbRCkSCkKBoJm5L4CQEDSmR5gHYAoENFAgkyadU/kF7hT+NwbGwCA42p9EwdmOf7bX2Xudg/Lp89nf/4MgGOKv6ABBHDskaoI5SNQEc5CoCeYgURPMQaImmINETTAHiZpgDhI1wRwbibqqzzBuKtFhgikUtEYDtNTo+OGTWNRqc4As/xPf83Xv+9t8FvksJqOqx48vi9ljzkcvBw/fGO9eRw3E3MYGKGiN7HtcmORqA+Nl+ah0wvnaxfN55+ygGo0F7vNtPkOv4kdC7y+UlzpyP6YQX+LOd9gkE7XawL+SCe3yDjVnqJa/xtn5hf95/QkLJt7dA9yJAAOGP7Q6Vukgi7ZzzjYMIRN6EZtQ1Wco8DqKfSsa2pAyevNn8N0SFk+poHWfwuTVzkmxD0j3rmDK6GUBzctZCX1ejp3sv4vaHOAt/YGiFpdh+z7FScl7R18fnVClg4I4RdEZL05SKAQnWO0O3/s8sruYdHskkair+Rug38JDNBBg4Rh3Isij8IGrYo+3OJOfnC9PGBoAf7qd3XmQLwLn3AVP+BoUSIg6cpfXyDkTu6ZPYXEnEAEAU5iW4AulkoPEhYtAUmr5a5wFCk2IyiUEo40vTmf1UdBKCzC67t8pSIscIFyGKnMtr8MQtpt0+yaBqBWc8hYmejQ5AdQG0oKBrpdABa37G5jabcxEWBULUsaVsOa6B44qp8AZI+c568hdXkBDxm756Q8Uz9flYHOqVwIs8xS9BSuUAs9ZMKcIdJ02DPA4DQn4CUODgyhvV1T2SQJRp8CvqSjRKq02v0GclGKr2aqYj4LWKAO+/59X9Y6OSgcFyYTmdQnb37r2SjNvUIj1wbuDk04wdO2OZgasEIBUA+O5DPN1WdcBJuaCvzpoEoh6DZUOsqEqXcY/EgdOenYqRAYCOEgvM7zp+oqY698UtEa2F1xsnUdCpYO3LKAFK7EqQ+QMT+QPcgl9S8DVlmuGVVhBOzj9cKzQFKbFQcqeoHvuWCX1FHxkPXSMJBD1FKYVbU0utj8LJc/xnP4isg0DFvqvFziT5RWxp9DiJl7Q7mp+lxWubLfoHe2MqM3BoqA9gnlMgefCUXdHYtvFMQA8DA1wouw9k2+F6uhOLMCzRXan9W2Sj8hzMN/j3sNhkkDUdbybS7xVJQeJC1bp7VCbMgQgUMmjAq7j3UREHKtxhVKQOIC7QWFhK20K0wLgLejW4U6sZ0icf6+2EO0uBQjIBrbuxk0FqN3hi2baXcnpUnw/bMNq9sP9/uLY3c7LCv413cn5eOtYHPt6BXGKotMlavlr39vPHUu0sJi21zS29z4OPiX6dy61gfHLCbqx1WfPxLX2LVGbA/ulL9tJ2Btl9OYZQFvuc/eF2hygwOsxYj9cElTqwL7ljlr0Zjg2YZeCdn4oOQRB2z86HYag/S3X4xE0Eldqh6o+w9XwAJJO/EEUtEbfgB/+fvuxsJGoCeKQSWY/COIIIFETzEGiJpiDRE0wB4maYA4SNcEcJGqCOUjUBHOQqAnmIFETzEGiJpiDRE0wB4maYI5fEVBqqy2sJ3oAAAAASUVORK5CYII="}}},{"cell_type":"markdown","source":"## Data Split","metadata":{}},{"cell_type":"code","source":"# 1) Split raw data & labels\n#    “data” here must be shape (N, 1, 128, 160)\n#    “labels” is shape (N,)\nX_trainval, X_test, y_trainval, y_test = train_test_split(\n    data, labels, test_size=0.3, stratify=labels, random_state=42\n)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_trainval, y_trainval, test_size=0.05, stratify=y_trainval, random_state=42\n)\n\n# 2) One‑hot encode labels\nenc = OneHotEncoder(sparse=False, handle_unknown='ignore')\ny_train = enc.fit_transform(y_train.reshape(-1, 1))\ny_val   = enc.transform   (y_val  .reshape(-1, 1))\ny_test  = enc.transform   (y_test .reshape(-1, 1))\n\n# 3) Scale pixel values per‑pixel\nns, _, _, _ = X_train.shape\nh, w, c    = 128, 160, 1  # known spectrogram dims\nscaler = StandardScaler()\n\nX_train = scaler.fit_transform(X_train.reshape(-1, h*w*c))\nX_val   = scaler.transform   (X_val  .reshape(-1, h*w*c))\nX_test  = scaler.transform   (X_test .reshape(-1, h*w*c))\n\nX_train = X_train.reshape(ns, h, w, c)\nX_val   = X_val.reshape(-1, h, w, c)\nX_test  = X_test.reshape(-1, h, w, c)\n\n# 4) TRANSPOSE ONCE: bring channels last\n# X_train = np.transpose(X_train, (0, 1, 2, 3))  # already (N,128,160,1), placeholder\n# X_val   = np.transpose(X_val,   (0, 1, 2, 3))\n# X_test  = np.transpose(X_test,  (0, 1, 2, 3))\n\n# (If your original data came in (N,1,128,160), use:)\n# X_train = np.transpose(X_train, (0, 2, 3, 1))\n# X_val   = np.transpose(X_val,   (0, 2, 3, 1))\n# X_test  = np.transpose(X_test,  (0, 2, 3, 1))\n\n\n\n# 5) Build tf.data.Dataset pipelines\ntrain_dataset = (\n    tf.data.Dataset\n      .from_tensor_slices((X_train, y_train))\n      .shuffle(2000)\n      .batch(64)\n      .prefetch(tf.data.AUTOTUNE)\n)\nval_dataset = (\n    tf.data.Dataset\n      .from_tensor_slices((X_val, y_val))\n      .batch(64)\n      .prefetch(tf.data.AUTOTUNE)\n)\ntest_dataset = (\n    tf.data.Dataset\n      .from_tensor_slices((X_test, y_test))\n      .batch(64)\n      .prefetch(tf.data.AUTOTUNE)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:19.385432Z","iopub.execute_input":"2025-05-15T00:01:19.385682Z","iopub.status.idle":"2025-05-15T00:01:23.675698Z","shell.execute_reply.started":"2025-05-15T00:01:19.385662Z","shell.execute_reply":"2025-05-15T00:01:23.675129Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(data.shape)    # Should be (7442, ...)\nprint(labels.shape)  # Should be (7442,) or (7442, 1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:23.676401Z","iopub.execute_input":"2025-05-15T00:01:23.676645Z","iopub.status.idle":"2025-05-15T00:01:23.680785Z","shell.execute_reply.started":"2025-05-15T00:01:23.676615Z","shell.execute_reply":"2025-05-15T00:01:23.679907Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nbatch = next(iter(train_dataset))\n\n# Unpack inputs and labels\ninputs, labels = batch\n\n# Print shapes\nprint(\"Inputs shape:\", inputs.shape)\nprint(\"Labels shape:\", labels.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:23.681514Z","iopub.execute_input":"2025-05-15T00:01:23.681745Z","iopub.status.idle":"2025-05-15T00:01:24.100291Z","shell.execute_reply.started":"2025-05-15T00:01:23.68173Z","shell.execute_reply":"2025-05-15T00:01:24.099562Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"def cnn_2d_model(input_shape, num_classes, filters, kernels):\n    model = models.Sequential([\n        layers.Conv2D(filters[0], kernel_size=kernels[0], strides=1, padding='same', activation='relu', input_shape=input_shape),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(pool_size=(2, 5), strides=(2, 2), padding='same'),\n\n        layers.Conv2D(filters[0], kernel_size=kernels[0], strides=1, padding='same', activation='relu'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(pool_size=(2, 5), strides=(2, 2), padding='same'),\n\n        layers.Conv2D(filters[1], kernel_size=kernels[1], strides=1, padding='same', activation='relu'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(pool_size=(2, 5), strides=(2, 2), padding='same'),\n\n        layers.Conv2D(filters[2], kernel_size=kernels[2], strides=1, padding='same', activation='relu'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(pool_size=(2, 3), strides=(2, 2), padding='same'),\n\n        layers.Flatten(),\n        layers.Dense(128, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    model.compile(optimizer='adam',\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:24.101164Z","iopub.execute_input":"2025-05-15T00:01:24.101679Z","iopub.status.idle":"2025-05-15T00:01:24.108142Z","shell.execute_reply.started":"2025-05-15T00:01:24.101653Z","shell.execute_reply":"2025-05-15T00:01:24.107427Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filter_sets_2d = [\n    (128, 128, 64, 64, 32),\n    (512, 256, 256, 128, 64),\n    (512, 512, 512, 256, 128)\n]\n\n\nkernel_sets_2d = [\n    [(1,3), (3,5), (3,5), (3,3), (3,3)],\n    [(3,5), (3,5), (3,5), (3,3), (3,3)],\n    [(5,5), (5,5), (3,5), (3,3), (1,3)]\n]\n\nearly_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:24.108852Z","iopub.execute_input":"2025-05-15T00:01:24.109134Z","iopub.status.idle":"2025-05-15T00:01:24.122449Z","shell.execute_reply.started":"2025-05-15T00:01:24.109106Z","shell.execute_reply":"2025-05-15T00:01:24.121936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    for gpu in gpus:\n        tf.config.experimental.set_memory_growth(gpu, True)\n    print(\"✅ GPU detected:\", gpus)\nelse:\n    print(\"❌ No GPU detected. Using CPU.\")\n\ninput_shape_2d = X_train.shape[1:] \nresults_2d = []\nnum_classes = 6\n\nfor filters in filter_sets_2d:\n    for kernels in kernel_sets_2d:\n        print(f\"\\nTraining 2D CNN: filters={filters}, kernels={kernels}\")\n        \n        model_2d = cnn_2d_model(input_shape_2d, num_classes, filters, kernels)\n        \n        history_2d = model_2d.fit(\n            train_dataset,\n            validation_data=val_dataset,\n            epochs=200,\n            callbacks=[early_stop],\n            verbose=0\n        )\n\n        y_pred_2d = model_2d.predict(val_dataset)\n        y_pred_classes_2d = np.argmax(y_pred_2d, axis=1)\n\n        y_true_classes_2d = np.concatenate(\n    [np.argmax(y, axis=1) for _, y in val_dataset.as_numpy_iterator()], axis=0)\n\n        val_acc_2d = max(history_2d.history['val_accuracy'])\n        f1_2d = f1_score(y_true_classes_2d, y_pred_classes_2d, average='weighted')\n\n        print(f\"→ Val Acc (2D): {val_acc_2d:.4f} | F1 Score (2D): {f1_2d:.4f} | Filters: {filters} | Kernels: {kernels}\")\n        results_2d.append(((filters, kernels), val_acc_2d, f1_2d))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:01:24.123082Z","iopub.execute_input":"2025-05-15T00:01:24.123306Z","iopub.status.idle":"2025-05-15T00:31:41.563914Z","shell.execute_reply.started":"2025-05-15T00:01:24.123292Z","shell.execute_reply":"2025-05-15T00:31:41.563348Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"full_dataset = (\n    tf.data.Dataset\n      .from_tensor_slices((np.concatenate([X_train, X_val], axis=0),\n                           np.concatenate([y_train, y_val], axis=0)))\n      .shuffle(2000)\n      .batch(64)\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:31:41.564595Z","iopub.execute_input":"2025-05-15T00:31:41.564869Z","iopub.status.idle":"2025-05-15T00:31:42.735714Z","shell.execute_reply.started":"2025-05-15T00:31:41.564851Z","shell.execute_reply":"2025-05-15T00:31:42.734964Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"early_stop = EarlyStopping(\n    monitor='accuracy',        # or 'accuracy' if preferred\n    patience=10,\n    restore_best_weights=True\n)\n\n\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    for gpu in gpus:\n        tf.config.experimental.set_memory_growth(gpu, True)\n    print(\"✅ GPU detected:\", gpus)\nelse:\n    print(\"❌ No GPU detected. Using CPU.\")\n\n# Model setup and training\nbest_filters = (128, 128, 64, 64, 32)\nbest_kernels = [(1, 3), (3, 5), (3, 5), (3, 3), (3, 3)]\nfinal_model = cnn_2d_model(input_shape_2d, num_classes, best_filters, best_kernels)\n\nhistory = final_model.fit(\n    full_dataset,\n    epochs=250,\n    callbacks=[early_stop],\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:32:00.008861Z","iopub.execute_input":"2025-05-15T00:32:00.009575Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_train_acc = history.history['accuracy'][-1]\nprint(f\"Final Train Accuracy: {final_train_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T00:57:26.428375Z","iopub.execute_input":"2025-05-15T00:57:26.428879Z","iopub.status.idle":"2025-05-15T00:57:26.432852Z","shell.execute_reply.started":"2025-05-15T00:57:26.428854Z","shell.execute_reply":"2025-05-15T00:57:26.432062Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6) Get predictions and compute F1 manually\ny_pred_probs = final_model.predict(test_dataset)\ny_pred_classes = np.argmax(y_pred_probs, axis=1)\n\n# Build true labels from test_dataset\ny_true_classes = np.concatenate([np.argmax(y, axis=1) for _, y in test_dataset], axis=0)\n\ntest_f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')\ntest_acc = accuracy_score(y_true_classes, y_pred_classes)\n\nprint(f\"Test Accuracy: {test_acc:.4f}\")\nprint(f\"Test F1 Score: {test_f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T01:04:02.194922Z","iopub.execute_input":"2025-05-15T01:04:02.195197Z","iopub.status.idle":"2025-05-15T01:04:02.706474Z","shell.execute_reply.started":"2025-05-15T01:04:02.195176Z","shell.execute_reply":"2025-05-15T01:04:02.705594Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels_dict = {'disgust': 1, 'happy': 2, 'sad': 3, 'neutral': 4, 'fear': 5, 'angry': 6}\n\n# Sort the keys based on their mapped values (1 to 6)\nclass_names = [k for k, v in sorted(labels_dict.items(), key=lambda item: item[1])]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T01:02:10.497014Z","iopub.execute_input":"2025-05-15T01:02:10.497661Z","iopub.status.idle":"2025-05-15T01:02:10.501917Z","shell.execute_reply.started":"2025-05-15T01:02:10.497635Z","shell.execute_reply":"2025-05-15T01:02:10.500994Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\ncm = confusion_matrix(y_true_classes, y_pred_classes)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\ndisp.plot(cmap=\"Blues\", xticks_rotation=45)\nplt.title(\"Test Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T01:02:12.261354Z","iopub.execute_input":"2025-05-15T01:02:12.261945Z","iopub.status.idle":"2025-05-15T01:02:12.515561Z","shell.execute_reply.started":"2025-05-15T01:02:12.261915Z","shell.execute_reply":"2025-05-15T01:02:12.514867Z"}},"outputs":[],"execution_count":null}]}